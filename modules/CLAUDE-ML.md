# CLAUDE-ML: Machine Learning Module  
> Loaded when ML/AI projects detected

## ğŸ¤– ML Architecture Context
```yaml
environment_management: "venv or conda"
framework_preference:
  training: "pytorch > tensorflow"
  fine_tuning: "LLaMA-Factory or transformers"
  data: "pandas + numpy"
  
project_structure:
  data/: "raw and processed"
  models/: "saved checkpoints"
  notebooks/: "exploration"
  src/: "training code"
  configs/: "hyperparameters"
```

## ğŸ“‹ ML Prerequisites Checklist
```bash
# Before ML work:
echo "=== ML PREREQUISITES ==="

# â–¡ Virtual environment active?
[[ -n "$VIRTUAL_ENV" ]] && echo "âœ“ venv active: $(basename $VIRTUAL_ENV)" || echo "âœ— No venv active"

# â–¡ GPU available?
python3 -c "import torch; print(f'âœ“ GPU: {torch.cuda.is_available()}')" 2>/dev/null || echo "âœ— PyTorch not found"

# â–¡ Data present?
[[ -d ./data ]] && echo "âœ“ Data directory exists" || echo "âš ï¸ No data directory"

# â–¡ Configs loaded?
[[ -f configs/config.yaml ]] && echo "âœ“ Config found" || echo "âš ï¸ No config file"

# â–¡ Tracking setup?
[[ -d .wandb ]] || [[ -d mlruns ]] && echo "âœ“ Experiment tracking ready" || echo "âš ï¸ No tracking setup"
```

## ğŸš« ML Non-Goals
**NEVER without permission:**
- âŒ Start expensive training runs
- âŒ Download large datasets
- âŒ Modify hyperparameters in active experiments
- âŒ Delete checkpoints or results
- âŒ Share model weights publicly
- âŒ Use production API keys for testing

## ğŸ”„ ML Pattern Discovery

### Training Patterns
```python
# DISCOVERED PATTERN: Standard training loop
# 1. Load config
# 2. Setup wandb/tensorboard
# 3. Initialize model
# 4. Load checkpoint if resuming
# 5. Training loop with validation
# 6. Save best checkpoint
# 7. Log metrics
```

### Data Pipeline Patterns  
```python
# DISCOVERED PATTERN: Data preprocessing
# 1. Raw data validation
# 2. Preprocessing pipeline
# 3. Train/val/test split
# 4. Cache processed data
# 5. DataLoader creation
```

## ğŸ¯ ML Success Criteria
- âœ… Reproducible results (seed set)
- âœ… Metrics logged and tracked
- âœ… Checkpoints saved regularly
- âœ… Memory usage monitored
- âœ… Gradients checked for NaN
- âœ… Validation improving or explained

## ğŸ”§ ML Session Handoff
```markdown
## ML SESSION HANDOFF
### Experiment State
- Experiment ID: [wandb/mlflow ID]
- Epoch: [current/total]
- Best metric: [value @ epoch]
- Last checkpoint: [path]

### Training Status
- Loss: [train/val]
- Learning rate: [current]
- GPU memory: [used/total]
- ETA: [estimated time]

### Recovery Commands
```bash
source venv/bin/activate
export CUDA_VISIBLE_DEVICES=0
python train.py --resume-from [checkpoint]
```
```

---
*Module: ML | Auto-loads when requirements.txt or environment.yml found*